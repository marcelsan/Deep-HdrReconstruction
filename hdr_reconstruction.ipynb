{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dc1198d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "import opt\n",
    "\n",
    "from lib.image import unnormalize\n",
    "from lib.img_io import load_image, writeLDR, writeEXR\n",
    "from lib.io import load_ckpt\n",
    "from lib.io import print_\n",
    "from lib.util import make_dirs\n",
    "from lib.util import get_saturated_regions\n",
    "from network.softconvmask import SoftConvNotLearnedMaskUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73e515b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91290440",
   "metadata": {},
   "source": [
    "# Image load routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156ebb7",
   "metadata": {},
   "source": [
    "Define a function for loading a single image. The function takes an image directory and an optional transformation to be applied to the loaded image and returns the transformed image and the corresponding saturation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f50bad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_tensor(input_dir, image_transform=None):\n",
    "    # load image\n",
    "    image = load_image(input_dir)\n",
    "\n",
    "    # get saturation mask\n",
    "    conv_mask = 1 - get_saturated_regions(image)\n",
    "    conv_mask = torch.from_numpy(conv_mask).permute(2,0,1)\n",
    "\n",
    "    # apply transform to input image\n",
    "    if image_transform is not None:\n",
    "        image = img_transform(image)\n",
    "\n",
    "    return image, conv_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6a8dd2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=opt.MEAN, std=opt.STD)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18881588",
   "metadata": {},
   "source": [
    "# Set dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ca01e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pre-trained weights.\n",
    "WEIGHTS_DIR = './data/ldr2hdr.pth'\n",
    "\n",
    "# Path to the image for inference.\n",
    "IMAGE_DIR = './data/0014.png'\n",
    "\n",
    "# Path to output directory where the final results will be saved.\n",
    "OUTPUT_DIR = './'\n",
    "\n",
    "# Name of the output image.\n",
    "OUTPUT_IMAGE_NAME = '0014'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08fa1d2",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4e1390fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNetwork [SoftConvNotLearnedMaskUNet] was created. Total number of parameters: 51.5 million. To see the architecture, do print(network).\n"
     ]
    }
   ],
   "source": [
    "model = SoftConvNotLearnedMaskUNet().to(device)\n",
    "model.print_network()\n",
    "load_ckpt(WEIGHTS_DIR, [('model', model)])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9865b3",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63dbb25",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ff1dcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = load_image_tensor(IMAGE_DIR, img_transform)\n",
    "image = image[None, ...]\n",
    "mask = mask[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "901a9256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Saturation: 35.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Saturation: %0.2f%%\" % (100.0*(1-mask.mean().item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a7a2d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 1024])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb56c24",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7761e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_img = model(image.to(device), mask.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661b1a3",
   "metadata": {},
   "source": [
    "## Obtain final image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4fcb7e",
   "metadata": {},
   "source": [
    "Compute the final HDR image by combining the well-exposed content of the input image (in the linear domain) and the output of the network in the saturated areas (eq. 1). To convert the input image to the linear domain, we use a gamma function to approximate the inverse of camera curve.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32501d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pytorch tensors to numpy.\n",
    "image = unnormalize(image).permute(0,2,3,1).numpy()[0,:,:,:]\n",
    "mask = mask.permute(0,2,3,1).numpy()[0,:,:,:]\n",
    "pred_img = pred_img.cpu().permute(0,2,3,1).numpy()[0,:,:,:]\n",
    "\n",
    "# Convert the predicted image from log to the linear domain.\n",
    "y_predict = np.exp(pred_img)-1\n",
    "\n",
    "# Transforms the input image to the linear domain by using a gamma\n",
    "# approximate to the inverse of camera curve. You can change this function\n",
    "# with a more accurate representation of the camera curve.\n",
    "gamma = np.power(image, 2)\n",
    "\n",
    "# Compute the final HDR image.\n",
    "H = mask*gamma + (1-mask)*y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff296eb",
   "metadata": {},
   "source": [
    "# Save images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6bd107",
   "metadata": {},
   "source": [
    "Save final image and the intermediare images for debugging purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dda210d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeLDR(mask, '{}/{}_mask.png'.format(OUTPUT_DIR, OUTPUT_IMAGE_NAME))\n",
    "writeEXR(H, '{}/{}.exr'.format(OUTPUT_DIR, OUTPUT_IMAGE_NAME))\n",
    "writeEXR(gamma, '{}/{}_gamma.exr'.format(OUTPUT_DIR, OUTPUT_IMAGE_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee1a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
